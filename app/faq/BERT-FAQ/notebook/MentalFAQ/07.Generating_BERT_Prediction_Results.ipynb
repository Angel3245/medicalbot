{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWIhLk6uIODF",
        "outputId": "981eb50a-6fec-4d60-f972-3a5e45d2fed5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence-transformers) (4.22.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence-transformers) (4.64.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence-transformers) (1.12.1+cu116)\n",
            "Requirement already satisfied: torchvision in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence-transformers) (0.13.1+cu116)\n",
            "Requirement already satisfied: numpy in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence-transformers) (1.23.3)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence-transformers) (1.1.3)\n",
            "Requirement already satisfied: scipy in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence-transformers) (1.9.3)\n",
            "Requirement already satisfied: nltk in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence-transformers) (3.7)\n",
            "Requirement already satisfied: sentencepiece in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence-transformers) (0.1.97)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sentence-transformers) (0.10.0)\n",
            "Requirement already satisfied: requests in c:\\users\\usuario\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.21.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.9.13)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: click in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk->sentence-transformers) (8.1.3)\n",
            "Requirement already satisfied: joblib in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from nltk->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchvision->sentence-transformers) (9.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\usuario\\appdata\\roaming\\python\\python39\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\usuario\\appdata\\roaming\\python\\python39\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\usuario\\appdata\\roaming\\python\\python39\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.9.24)\n"
          ]
        }
      ],
      "source": [
        "# install required libraries\n",
        "!pip3 install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHrXaJsSLhrJ",
        "outputId": "bffc2663-f897-44d6-b4dc-e5d80c4f1f12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: elasticsearch in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (7.17.8)\n",
            "Requirement already satisfied: certifi in c:\\users\\usuario\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from elasticsearch) (2022.9.24)\n",
            "Requirement already satisfied: urllib3<2,>=1.21.1 in c:\\users\\usuario\\appdata\\roaming\\python\\python39\\site-packages (from elasticsearch) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install elasticsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Nx6PkXGeh5s3"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-v9U9E5h5gb",
        "outputId": "8d0c5e0c-9d9f-4762-f076-26aceac1dbe8"
      },
      "outputs": [],
      "source": [
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMP1Wg7Bh5RT",
        "outputId": "ff8a9744-480a-422e-8630-47dd8e6f0b6d"
      },
      "outputs": [],
      "source": [
        "#%cd /content/drive/MyDrive/BERT-FAQ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ESSxl0XiXAD",
        "outputId": "96a70ca6-5e40-41a1-966b-73e983909149"
      },
      "outputs": [],
      "source": [
        "#!ls\n",
        "import sys\n",
        "sys.path.insert(0, \"../../../BERT-FAQ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Fu6mIC_NKTRR"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# import required dependencies\n",
        "from evaluation import get_relevance_label_df\n",
        "from shared.utils import load_from_json\n",
        "from shared.utils import dump_to_json\n",
        "from shared.utils import make_dirs\n",
        "from reranker import ReRanker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_O3F8NYk19Go"
      },
      "outputs": [],
      "source": [
        "output_path=\"../../../BERT-FAQ/data/MentalFAQ/rank_results\"\n",
        "\n",
        "# load user_query ES results from json files\n",
        "es_output_path = output_path + \"/unsupervised\"\n",
        "es_query_by_question = load_from_json(es_output_path + '/es_query_by_question.json')\n",
        "es_query_by_answer = load_from_json(es_output_path + '/es_query_by_answer.json')\n",
        "es_query_by_question_answer = load_from_json(es_output_path + '/es_query_by_question_answer.json')\n",
        "es_query_by_question_answer_concat = load_from_json(es_output_path + '/es_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pyA4nPfi1885"
      },
      "outputs": [],
      "source": [
        "# load test_queries, relevance_label_df for ReRanker\n",
        "query_answer_pair_filepath = '../../../BERT-FAQ/data/MentalFAQ/query_answer_pairs.json'\n",
        "relevance_label_df = get_relevance_label_df(query_answer_pair_filepath)\n",
        "test_queries = relevance_label_df[relevance_label_df['query_type'] == 'user_query'].question.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhodYHua180S",
        "outputId": "a16473d4-472b-4471-f420-49860bb2260f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['What does it mean to have a mental illness?',\n",
              "       'Who does mental illness affect?', 'What causes mental illness?',\n",
              "       'What are some of the warning signs of mental illness?',\n",
              "       'Can people with mental illness recover?',\n",
              "       'What should I do if I know someone who appears to have the symptoms of a mental disorder?',\n",
              "       'How can I find a mental health professional for myself or my child?',\n",
              "       'What treatment options are available?',\n",
              "       'If I become involved in treatment, what do I need to know?',\n",
              "       'What is the difference between mental health professionals?'],\n",
              "      dtype=object)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_queries[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2S73_R42DCF",
        "outputId": "79e86c1e-2dd6-411a-d000-0f5fd4a2604e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "98"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# total number of test queries\n",
        "len(test_queries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDsNe63Nix7W"
      },
      "source": [
        "**1. Generating BERT prediction results from Answer (BERT-Q-a)\"**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "dvplanC2jY-y"
      },
      "outputs": [],
      "source": [
        "# define rank_field parameter\n",
        "rank_field=\"BERT-Q-a\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxcqS2Dj2liG"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"hard\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "__jcFHSRBZSY"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "n9ycYBipNnP9"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xJMgG4aZKTN5",
        "outputId": "7b1c2e6c-761c-4503-c081-af8466b18f28"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 19:23:32 - Generating BERT top-k results ...\n",
            "2022-12-14 19:23:32 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_user_query_1.1\n",
            "2022-12-14 19:23:33 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:31<00:00,  1.07it/s]\n",
            "2022-12-14 19:25:05 - Generating BERT top-k results ...\n",
            "2022-12-14 19:25:05 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_user_query_1.1\n",
            "2022-12-14 19:25:05 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [02:16<00:00,  1.39s/it]\n",
            "2022-12-14 19:27:22 - Generating BERT top-k results ...\n",
            "2022-12-14 19:27:22 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_user_query_1.1\n",
            "2022-12-14 19:27:22 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [02:17<00:00,  1.41s/it]\n",
            "2022-12-14 19:29:40 - Generating BERT top-k results ...\n",
            "2022-12-14 19:29:40 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_user_query_1.1\n",
            "2022-12-14 19:29:41 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [02:18<00:00,  1.41s/it]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni5fBXXCM8oo"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"simple\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YahPWqlrM4eU"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "vfz-PNgZM4FL"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90jQn9shzcsj",
        "outputId": "f241c875-02db-433d-ed10-9258a8909017"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 19:31:59 - Generating BERT top-k results ...\n",
            "2022-12-14 19:31:59 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_user_query_1.1\n",
            "2022-12-14 19:32:00 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:28<00:00,  1.11it/s]\n",
            "2022-12-14 19:33:29 - Generating BERT top-k results ...\n",
            "2022-12-14 19:33:29 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_user_query_1.1\n",
            "2022-12-14 19:33:29 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [02:15<00:00,  1.38s/it]\n",
            "2022-12-14 19:35:45 - Generating BERT top-k results ...\n",
            "2022-12-14 19:35:45 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_user_query_1.1\n",
            "2022-12-14 19:35:45 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [02:18<00:00,  1.42s/it]\n",
            "2022-12-14 19:38:04 - Generating BERT top-k results ...\n",
            "2022-12-14 19:38:04 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_user_query_1.1\n",
            "2022-12-14 19:38:05 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [02:18<00:00,  1.41s/it]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0-VLGZ-Np04"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"hard\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "sGUqO4kSNcGJ"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Bkdb3DQON4A9"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9whF6pZTzfHK",
        "outputId": "0d7b2711-31b2-4b6b-d11b-e36af65d2101"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 19:40:24 - Generating BERT top-k results ...\n",
            "2022-12-14 19:40:24 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_faq_1.1\n",
            "2022-12-14 19:40:24 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:28<00:00,  1.10it/s]\n",
            "2022-12-14 19:41:53 - Generating BERT top-k results ...\n",
            "2022-12-14 19:41:53 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_faq_1.1\n",
            "2022-12-14 19:41:54 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [02:16<00:00,  1.39s/it]\n",
            "2022-12-14 19:44:10 - Generating BERT top-k results ...\n",
            "2022-12-14 19:44:10 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_faq_1.1\n",
            "2022-12-14 19:44:11 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [02:18<00:00,  1.42s/it]\n",
            "2022-12-14 19:46:30 - Generating BERT top-k results ...\n",
            "2022-12-14 19:46:30 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_faq_1.1\n",
            "2022-12-14 19:46:30 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [02:18<00:00,  1.42s/it]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW6WhP1POh4R"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"simple\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "td1x8prBOXIo"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Z8ZPxcmWOny9"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWO9iOd4zjrX",
        "outputId": "036e921d-8615-4739-da66-84bbc020b268"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 19:48:49 - Generating BERT top-k results ...\n",
            "2022-12-14 19:48:49 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_faq_1.1\n",
            "2022-12-14 19:48:50 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:29<00:00,  1.10it/s]\n",
            "2022-12-14 19:50:19 - Generating BERT top-k results ...\n",
            "2022-12-14 19:50:19 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_faq_1.1\n",
            "2022-12-14 19:50:20 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [02:15<00:00,  1.39s/it]\n",
            "2022-12-14 19:52:36 - Generating BERT top-k results ...\n",
            "2022-12-14 19:52:36 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_faq_1.1\n",
            "2022-12-14 19:52:36 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [02:18<00:00,  1.41s/it]\n",
            "2022-12-14 19:54:55 - Generating BERT top-k results ...\n",
            "2022-12-14 19:54:55 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_faq_1.1\n",
            "2022-12-14 19:54:56 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [02:18<00:00,  1.41s/it]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQWBMnXNuN1r"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"hard\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "qWbql3bypSdF"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "nXbORhXguIpu"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxveUtZbzlnb",
        "outputId": "3e8b16c2-82a0-454a-ae32-dbb6b1a1905c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 19:57:14 - Generating BERT top-k results ...\n",
            "2022-12-14 19:57:15 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:58<00:00,  1.69it/s]\n",
            "2022-12-14 19:58:13 - Generating BERT top-k results ...\n",
            "2022-12-14 19:58:14 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:26<00:00,  1.13it/s]\n",
            "2022-12-14 19:59:41 - Generating BERT top-k results ...\n",
            "2022-12-14 19:59:41 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:29<00:00,  1.10it/s]\n",
            "2022-12-14 20:01:11 - Generating BERT top-k results ...\n",
            "2022-12-14 20:01:11 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:29<00:00,  1.09it/s]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toLHtw4zugOk"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"simple\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "SBPKGt7ktRLQ"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8zMO_kPHtRBO"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vUWF6aUzmvS",
        "outputId": "d6fe0a73-1af3-47e7-d648-55a5114854d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 20:02:41 - Generating BERT top-k results ...\n",
            "2022-12-14 20:02:42 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:58<00:00,  1.69it/s]\n",
            "2022-12-14 20:03:40 - Generating BERT top-k results ...\n",
            "2022-12-14 20:03:41 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:26<00:00,  1.14it/s]\n",
            "2022-12-14 20:05:07 - Generating BERT top-k results ...\n",
            "2022-12-14 20:05:07 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:26<00:00,  1.13it/s]\n",
            "2022-12-14 20:06:34 - Generating BERT top-k results ...\n",
            "2022-12-14 20:06:35 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:28<00:00,  1.11it/s]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNDZBk_GvM1z"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"hard\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "VmtGmXzrtQda"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "pzg0l8rEtQZh"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q_F0a8Qzon2",
        "outputId": "5307fd6e-c7b7-448d-ddb9-766ed5236789"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 20:08:03 - Generating BERT top-k results ...\n",
            "2022-12-14 20:08:04 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:58<00:00,  1.68it/s]\n",
            "2022-12-14 20:09:02 - Generating BERT top-k results ...\n",
            "2022-12-14 20:09:03 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:26<00:00,  1.13it/s]\n",
            "2022-12-14 20:10:30 - Generating BERT top-k results ...\n",
            "2022-12-14 20:10:30 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:29<00:00,  1.10it/s]\n",
            "2022-12-14 20:11:59 - Generating BERT top-k results ...\n",
            "2022-12-14 20:12:00 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:31<00:00,  1.07it/s]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2EgbhAkvgUc"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"simple\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "4tUfy5fOtP2M"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "x94VfKuitPva"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzcVcYUwzqLm",
        "outputId": "545a3cf6-ef94-4d9a-a667-96b393e07e3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 20:13:32 - Generating BERT top-k results ...\n",
            "2022-12-14 20:13:33 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:57<00:00,  1.70it/s]\n",
            "2022-12-14 20:14:31 - Generating BERT top-k results ...\n",
            "2022-12-14 20:14:31 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:27<00:00,  1.11it/s]\n",
            "2022-12-14 20:15:59 - Generating BERT top-k results ...\n",
            "2022-12-14 20:16:00 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:30<00:00,  1.08it/s]\n",
            "2022-12-14 20:17:31 - Generating BERT top-k results ...\n",
            "2022-12-14 20:17:31 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:29<00:00,  1.09it/s]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRyZyUa9kTKP"
      },
      "source": [
        "**2. Generating BERT prediction results from Question (BERT-Q-q)\"**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "JYQ_Ixk4kZp6"
      },
      "outputs": [],
      "source": [
        "# define rank_field parameter\n",
        "rank_field=\"BERT-Q-q\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZXbr22mlcPA"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"hard\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "GkAAGDUrlWKr"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "xXmZkX1mlWDG"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47GyLe1BlV7l",
        "outputId": "1fce8c14-d3a0-4b1d-a072-4ff1515c43e0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 20:19:02 - Generating BERT top-k results ...\n",
            "2022-12-14 20:19:02 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_user_query_1.1\n",
            "2022-12-14 20:19:02 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:42<00:00,  2.31it/s]\n",
            "2022-12-14 20:19:45 - Generating BERT top-k results ...\n",
            "2022-12-14 20:19:45 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_user_query_1.1\n",
            "2022-12-14 20:19:45 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:00<00:00,  1.61it/s]\n",
            "2022-12-14 20:20:46 - Generating BERT top-k results ...\n",
            "2022-12-14 20:20:46 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_user_query_1.1\n",
            "2022-12-14 20:20:47 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:02<00:00,  1.56it/s]\n",
            "2022-12-14 20:21:50 - Generating BERT top-k results ...\n",
            "2022-12-14 20:21:50 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_user_query_1.1\n",
            "2022-12-14 20:21:51 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:02<00:00,  1.56it/s]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM5qc6jrl1DE"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"simple\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "uW6EmCdAlVzK"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "z6poNdx0lVrh"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOJ8nTMslVkJ",
        "outputId": "9dd38f36-e1f7-46d6-d63f-bf78045e3a3b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 20:22:54 - Generating BERT top-k results ...\n",
            "2022-12-14 20:22:54 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_user_query_1.1\n",
            "2022-12-14 20:22:54 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:42<00:00,  2.33it/s]\n",
            "2022-12-14 20:23:36 - Generating BERT top-k results ...\n",
            "2022-12-14 20:23:36 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_user_query_1.1\n",
            "2022-12-14 20:23:37 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:01<00:00,  1.59it/s]\n",
            "2022-12-14 20:24:39 - Generating BERT top-k results ...\n",
            "2022-12-14 20:24:39 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_user_query_1.1\n",
            "2022-12-14 20:24:39 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:03<00:00,  1.54it/s]\n",
            "2022-12-14 20:25:43 - Generating BERT top-k results ...\n",
            "2022-12-14 20:25:43 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_user_query_1.1\n",
            "2022-12-14 20:25:44 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:03<00:00,  1.54it/s]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YycMuPkZoHSJ"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"hard\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "1V5_byZblVT0"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "leu15hKDlVMo"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDdzleOUlVFB",
        "outputId": "96693252-50bc-48d2-f02f-a60228b33a05"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 20:26:48 - Generating BERT top-k results ...\n",
            "2022-12-14 20:26:48 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_faq_1.1\n",
            "2022-12-14 20:26:48 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:42<00:00,  2.32it/s]\n",
            "2022-12-14 20:27:31 - Generating BERT top-k results ...\n",
            "2022-12-14 20:27:31 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_faq_1.1\n",
            "2022-12-14 20:27:31 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:01<00:00,  1.59it/s]\n",
            "2022-12-14 20:28:33 - Generating BERT top-k results ...\n",
            "2022-12-14 20:28:33 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_faq_1.1\n",
            "2022-12-14 20:28:33 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:02<00:00,  1.56it/s]\n",
            "2022-12-14 20:29:37 - Generating BERT top-k results ...\n",
            "2022-12-14 20:29:37 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_hard_faq_1.1\n",
            "2022-12-14 20:29:37 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:03<00:00,  1.55it/s]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugHFLDp3oLKm"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"simple\"; loss_type='triplet'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "0eEmYNyYlU5h"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='triplet'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "eZhB3zuSlUyb"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qee6WH2blUqi",
        "outputId": "6617923b-f7a4-4879-b4e5-0c76cda5d4c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 20:30:41 - Generating BERT top-k results ...\n",
            "2022-12-14 20:30:41 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_faq_1.1\n",
            "2022-12-14 20:30:41 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:41<00:00,  2.35it/s]\n",
            "2022-12-14 20:31:23 - Generating BERT top-k results ...\n",
            "2022-12-14 20:31:23 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_faq_1.1\n",
            "2022-12-14 20:31:23 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:00<00:00,  1.61it/s]\n",
            "2022-12-14 20:32:24 - Generating BERT top-k results ...\n",
            "2022-12-14 20:32:24 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_faq_1.1\n",
            "2022-12-14 20:32:25 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:03<00:00,  1.55it/s]\n",
            "2022-12-14 20:33:28 - Generating BERT top-k results ...\n",
            "2022-12-14 20:33:28 - Load pretrained SentenceTransformer: ../../../BERT-FAQ/output/MentalFAQ/models/triplet_simple_faq_1.1\n",
            "2022-12-14 20:33:29 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [01:04<00:00,  1.52it/s]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqE2Blb3oPw1"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"hard\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "C8noZJecmltk"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "U_iwsKK6mljZ"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkfY7SAAmlZy",
        "outputId": "be62e021-714c-4e59-cd61-e012ae530713"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 20:34:33 - Generating BERT top-k results ...\n",
            "2022-12-14 20:34:34 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:38<00:00,  2.54it/s]\n",
            "2022-12-14 20:35:13 - Generating BERT top-k results ...\n",
            "2022-12-14 20:35:13 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:55<00:00,  1.77it/s]\n",
            "2022-12-14 20:36:09 - Generating BERT top-k results ...\n",
            "2022-12-14 20:36:09 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:57<00:00,  1.71it/s]\n",
            "2022-12-14 20:37:07 - Generating BERT top-k results ...\n",
            "2022-12-14 20:37:07 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:57<00:00,  1.71it/s]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lO2b2wxoUWS"
      },
      "source": [
        "**query_type=\"user_query\"; neg_type=\"simple\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "lctMrtS0mlHO"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"user_query\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "H-NvD-Sgmk9l"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sIIkgKhmk4C",
        "outputId": "c22f1435-da4a-4661-8f81-e5160a197408"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 20:38:05 - Generating BERT top-k results ...\n",
            "2022-12-14 20:38:05 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:38<00:00,  2.52it/s]\n",
            "2022-12-14 20:38:44 - Generating BERT top-k results ...\n",
            "2022-12-14 20:38:45 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:56<00:00,  1.73it/s]\n",
            "2022-12-14 20:39:42 - Generating BERT top-k results ...\n",
            "2022-12-14 20:39:42 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:58<00:00,  1.68it/s]\n",
            "2022-12-14 20:40:41 - Generating BERT top-k results ...\n",
            "2022-12-14 20:40:42 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:58<00:00,  1.67it/s]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcXgJnWboXMy"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"hard\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "uU_9X36LnNNi"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"hard\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "KdUQo5RznNCE"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjDLglyJnM28",
        "outputId": "00175dce-5db9-44b1-9677-ede302ceeea7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 20:41:41 - Generating BERT top-k results ...\n",
            "2022-12-14 20:41:41 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:38<00:00,  2.55it/s]\n",
            "2022-12-14 20:42:20 - Generating BERT top-k results ...\n",
            "2022-12-14 20:42:20 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:55<00:00,  1.75it/s]\n",
            "2022-12-14 20:43:16 - Generating BERT top-k results ...\n",
            "2022-12-14 20:43:17 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:58<00:00,  1.68it/s]\n",
            "2022-12-14 20:44:15 - Generating BERT top-k results ...\n",
            "2022-12-14 20:44:16 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:58<00:00,  1.67it/s]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZubZiiwqobdT"
      },
      "source": [
        "**query_type=\"faq\"; neg_type=\"simple\"; loss_type='softmax'**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "aEoVIgvQnMf-"
      },
      "outputs": [],
      "source": [
        "# define variables\n",
        "query_type=\"faq\"; neg_type=\"simple\"; version=\"1.1\"; loss_type='softmax'\n",
        "bert_model_path='../../../BERT-FAQ/output/MentalFAQ/models/' + loss_type + '_' + neg_type + '_' + query_type + '_' + version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "ZaVyBLM9nMUn"
      },
      "outputs": [],
      "source": [
        "# create instance of ReRanker class\n",
        "r = ReRanker(\n",
        "    bert_model_path=bert_model_path, \n",
        "    test_queries=test_queries, relevance_label_df=relevance_label_df,\n",
        "    rank_field=rank_field\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydEelLV-nMIn",
        "outputId": "74376544-158c-46ca-8fba-6cef8f0214c4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-12-14 20:45:15 - Generating BERT top-k results ...\n",
            "2022-12-14 20:45:15 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:39<00:00,  2.50it/s]\n",
            "2022-12-14 20:45:54 - Generating BERT top-k results ...\n",
            "2022-12-14 20:45:55 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:55<00:00,  1.75it/s]\n",
            "2022-12-14 20:46:51 - Generating BERT top-k results ...\n",
            "2022-12-14 20:46:52 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:58<00:00,  1.67it/s]\n",
            "2022-12-14 20:47:50 - Generating BERT top-k results ...\n",
            "2022-12-14 20:47:51 - Use pytorch device: cuda\n",
            "100%|██████████| 98/98 [00:58<00:00,  1.68it/s]\n"
          ]
        }
      ],
      "source": [
        "# generate directory structure\n",
        "pred_output_path = output_path + \"/supervised/\" + rank_field + \"/\" + loss_type + \"/\" + query_type + \"/\" + neg_type\n",
        "make_dirs(pred_output_path)\n",
        "\n",
        "# next, generate BERT, Re-ranked top-k results and dump to files\n",
        "bert_query_by_question = r.get_bert_topk_preds(es_query_by_question)\n",
        "dump_to_json(bert_query_by_question, pred_output_path + '/bert_query_by_question.json')\n",
        "\n",
        "bert_query_by_answer = r.get_bert_topk_preds(es_query_by_answer)\n",
        "dump_to_json(bert_query_by_answer, pred_output_path + '/bert_query_by_answer.json')\n",
        "\n",
        "bert_query_by_question_answer = r.get_bert_topk_preds(es_query_by_question_answer)\n",
        "dump_to_json(bert_query_by_question_answer, pred_output_path + '/bert_query_by_question_answer.json')\n",
        "\n",
        "bert_query_by_question_answer_concat = r.get_bert_topk_preds(es_query_by_question_answer_concat)\n",
        "dump_to_json(bert_query_by_question_answer_concat, pred_output_path + '/bert_query_by_question_answer_concat.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HbmSw6KqVuEH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "07.Generating_BERT_Prediction_Results.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "4a642a9a94d05d387b7a27be99b5a4ff6656c8c24931cc81c2f78dd14cfb5dc8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
